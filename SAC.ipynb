{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Zygote\n",
    "using PyCall\n",
    "using DataStructures\n",
    "using StatsBase\n",
    "using Printf\n",
    "using LinearAlgebra\n",
    "using Distributions\n",
    "using DistributionsAD\n",
    "using Test\n",
    "using BSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Any} with 18 entries:\n",
       "  \"value_layer2\"         => 32\n",
       "  \"lr\"                   => 0.001\n",
       "  \"policy_layer2\"        => 32\n",
       "  \"discount_factor\"      => 0.99\n",
       "  \"train_steps_per_iter\" => 2\n",
       "  \"batch_size\"           => 100\n",
       "  \"steps_per_epoch\"      => 2000\n",
       "  \"env\"                  => \"CartPoleContinuousBulletEnv-v0\"\n",
       "  \"buffer_size\"          => 1000000\n",
       "  \"l2_reg\"               => 0.0001\n",
       "  \"q_layer1\"             => 32\n",
       "  \"target_update\"        => 0.001\n",
       "  \"policy_layer1\"        => 32\n",
       "  \"value_layer1\"         => 32\n",
       "  \"activation\"           => swish\n",
       "  \"epochs\"               => 100\n",
       "  \"entropy_incentive\"    => 0.2\n",
       "  \"q_layer2\"             => 32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_size = 32\n",
    "\n",
    "hparams = Dict([\n",
    "    (\"lr\", 1e-3),\n",
    "    (\"env\", \"CartPoleContinuousBulletEnv-v0\"),\n",
    "    (\"policy_layer1\", layer_size),\n",
    "    (\"policy_layer2\", layer_size),\n",
    "    (\"value_layer1\", layer_size),\n",
    "    (\"value_layer2\", layer_size),\n",
    "    (\"q_layer1\", layer_size),\n",
    "    (\"q_layer2\", layer_size),\n",
    "    (\"activation\", swish),\n",
    "    (\"target_update\", 1e-3),\n",
    "    (\"entropy_incentive\", 0.2),\n",
    "    (\"l2_reg\", 1e-4),\n",
    "    (\"batch_size\", 100),\n",
    "    (\"discount_factor\", 0.99),\n",
    "    (\"buffer_size\", 1000000),\n",
    "    (\"epochs\", 100),\n",
    "    (\"steps_per_epoch\", 2000),\n",
    "    (\"train_steps_per_iter\", 2)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jul  8 2020 18:24:12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyimport(\"pybullet_envs\")\n",
    "gym = pyimport(\"gym\")\n",
    "env = gym.make(hparams[\"env\"])\n",
    "\n",
    "\n",
    "STATE_SPACE = length(env.observation_space.low)\n",
    "ACTION_SPACE = length(env.action_space.low)\n",
    "ACTION_HIGH = env.action_space.high\n",
    "ACTION_LOW = env.action_space.low\n",
    "TARGET_UPDATE = hparams[\"target_update\"]\n",
    "ENTROPY_INCENTIVE = hparams[\"entropy_incentive\"]\n",
    "L2_REG = hparams[\"l2_reg\"]\n",
    "BATCH_SIZE = hparams[\"batch_size\"]\n",
    "GAMMA = hparams[\"discount_factor\"]\n",
    "EPOCHS = hparams[\"epochs\"]\n",
    "STEPS_PER_EPOCH = hparams[\"steps_per_epoch\"]\n",
    "TRAIN_STEPS_PER_ITER = hparams[\"train_steps_per_iter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = Flux.ADAM(hparams[\"lr\"])\n",
    "dtype = Float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "support_to_action (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our squashed policy has a support of -1,1\n",
    "# Project actions to/from that support\n",
    "function action_to_support(action)\n",
    "    halfspan = (ACTION_HIGH .- ACTION_LOW) ./ 2\n",
    "    low_end = ACTION_LOW ./ halfspan\n",
    "    action ./ halfspan .- low_end .- 1\n",
    "end\n",
    "\n",
    "function support_to_action(action)\n",
    "    halfspan = (ACTION_HIGH .- ACTION_LOW) ./ 2\n",
    "    low_end = ACTION_LOW ./ halfspan\n",
    "    (action .+ 1 .+ low_end) .* halfspan\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin\n",
    "    local lol1 = Flux.batch([rand(ACTION_SPACE) for _ in 1:100])\n",
    "    @test isapprox(lol1, support_to_action(action_to_support(lol1)))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initialize (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initialize()\n",
    "    \n",
    "    typeswitch(T, x) = x\n",
    "    typeswitch(T, x::Number) = T(x)\n",
    "    typeswitch(T, x::AbstractArray) = T.(x)\n",
    "    \n",
    "    value = Chain(\n",
    "        Dense(STATE_SPACE, hparams[\"value_layer1\"], hparams[\"activation\"]),\n",
    "        #LayerNorm(hparams[\"value_layer1\"]),\n",
    "        Dense(hparams[\"value_layer1\"], hparams[\"value_layer2\"], hparams[\"activation\"]),\n",
    "        #LayerNorm(hparams[\"value_layer2\"]),\n",
    "        Dense(hparams[\"value_layer2\"], 1),\n",
    "    )\n",
    "    value = Flux.fmap(x -> typeswitch(dtype, x), value)\n",
    "\n",
    "    value_target = deepcopy(value)\n",
    "\n",
    "    critics = map((_) -> Flux.fmap(x -> typeswitch(dtype, x), Chain(\n",
    "        Dense(STATE_SPACE+ACTION_SPACE, hparams[\"q_layer1\"], hparams[\"activation\"]),\n",
    "        #LayerNorm(hparams[\"q_layer1\"]),\n",
    "        Dense(hparams[\"q_layer1\"], hparams[\"q_layer2\"], hparams[\"activation\"]),\n",
    "        #LayerNorm(hparams[\"q_layer2\"]),\n",
    "        Dense(hparams[\"q_layer2\"], 1),\n",
    "    )), 1:2)\n",
    "\n",
    "    policy = Chain(\n",
    "        Dense(STATE_SPACE, hparams[\"policy_layer1\"], hparams[\"activation\"]),\n",
    "        #LayerNorm(hparams[\"policy_layer1\"]),\n",
    "        Dense(hparams[\"policy_layer1\"], hparams[\"policy_layer2\"], hparams[\"activation\"]),\n",
    "        #LayerNorm(hparams[\"policy_layer2\"]),\n",
    "        Dense(hparams[\"policy_layer2\"], ACTION_SPACE*2),\n",
    "    )\n",
    "    policy = Flux.fmap(x -> typeswitch(dtype, x), policy)\n",
    "\n",
    "    \n",
    "    memory = memory = CircularBuffer{Tuple{Array{dtype,1}, Array{dtype, 1}, dtype, Array{dtype,1}, Bool}}(hparams[\"buffer_size\"])\n",
    "    \n",
    "    value, value_target, critics, policy, memory\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward_critic (generic function with 2 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Single value mode\n",
    "function forward_critic(models, state::Array{T,1}, action::Array{T,1}) where {T}\n",
    "    pred = map((model) -> model(vcat(state, action)), models)\n",
    "    minimum(Flux.stack(pred, 1))\n",
    "end\n",
    "# Batch mode\n",
    "function forward_critic(models, state::Array{T,2}, action::Array{T,2}) where {T}\n",
    "    pred = map((model) -> dropdims(model(vcat(state, action)), dims=1), models)\n",
    "    minimum(Flux.stack(pred, 1), dims=1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logprobs_cuda (generic function with 2 methods)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "function forward_policy(model, state::Array{T, 2}) where {T}\n",
    "    x = policy(state)\n",
    "    mu = x[1:ACTION_SPACE,:]\n",
    "    sigma = exp.(x[ACTION_SPACE+1:end,:])\n",
    "    return mu, sigma\n",
    "end\n",
    "function forward_policy(model, state::Array{T, 1}) where {T}\n",
    "    x = policy(state)\n",
    "    mu = x[1:ACTION_SPACE]\n",
    "    sigma = exp.(x[ACTION_SPACE+1:end])\n",
    "    return mu, sigma\n",
    "end\n",
    "\n",
    "# The SAC authors squash their action space\n",
    "# See Appendix C in their paper\n",
    "function squash(actions)\n",
    "    tanh.(actions)\n",
    "end\n",
    "function policy_sample(mu::Array{T}, sigma::Array{T}) where {T}\n",
    "    mu .+ sigma .* clamp.(T.(rand(Normal(), size(sigma))), -10, 10)\n",
    "end\n",
    "function policy_sample(model, state::Array)\n",
    "    policy_sample(forward_policy(model, state)...)\n",
    "end\n",
    "function act(model, state)\n",
    "    support_to_action(squash(policy_sample(model, state)))\n",
    "end\n",
    "function logprob(mu, sigma, action_unsquashed::Array{T}) where {T}\n",
    "    # Add a small epsilon so we don't explode the loss\n",
    "    logpdf(TuringDiagMvNormal(mu, sigma), action_unsquashed) - sum(log.(1 .- tanh.(action_unsquashed) .^ 2 .+ eps(T) ))\n",
    "end\n",
    "# function logprobs(mu, sigma, actions_unsquashed)\n",
    "#     mapslices(\n",
    "#         (x) -> logprob(x[1:ACTION_SPACE], x[ACTION_SPACE+1:ACTION_SPACE*2], x[ACTION_SPACE*2+1:end]), \n",
    "#         [mu;sigma;actions_unsquashed], dims=2\n",
    "#     )\n",
    "# end\n",
    "\n",
    "# Copied from DistributionsAD\n",
    "# function logprob_cuda(mu, sigma, x)\n",
    "#     -(length(x) * log(2*pi) + 2 * sum(log.(sigma)) + sum(((x .- mu) ./ sigma) .^ 2)) / 2\n",
    "# end\n",
    "\n",
    "function logprobs_cuda(mu::AbstractArray{T, 2}, sigma::AbstractArray{T, 2}, x::AbstractArray{T, 2}) where {T}\n",
    "    # A pretty intimidating function\n",
    "    # The first half is the normal logpdf part, copied from DistributionsAD for a diagonal multivariate gaussian where the sums are respecting batching\n",
    "    # The second part is needed because the function is squashed with tanh\n",
    "    -(size(mu, 1) * log(2*pi) .+ 2 * sum(log.(sigma), dims=1) .+ sum(((x .- mu) ./ sigma) .^ 2, dims=1)) / 2 .- sum(log.(1 .- tanh.(x) .^ 2 .+ eps(T)), dims=1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = rand(10)\n",
    "sigma = rand(10) .^2\n",
    "action = mu .+ sigma .* rand(Normal(), 10)\n",
    "\n",
    "mus = Flux.batch([mu, mu, mu])\n",
    "sigmas = Flux.batch([sigma, sigma, sigma])\n",
    "actions = Flux.batch([action, action, action])\n",
    "\n",
    "@test isapprox(logprob(mu, sigma, action), logprobs_cuda(mus, sigmas, actions)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.433451663275275"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprob(mu, sigma, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×3 Array{Float64,2}:\n",
       " 24.4335  24.4335  24.4335"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs_cuda(mus, sigmas, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×100 Array{Float64,2}:\n",
       " -0.557655  -0.735788  -0.741822  …  -0.530643  -0.734148  -0.570652"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = repeat(rand(STATE_SPACE), 1,100)\n",
    "mu, sigma = forward_policy(policy, states)\n",
    "a = policy_sample(mu, sigma)\n",
    "y = logprobs(mu, sigma, a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_value! (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_value_target!(value_target, value)\n",
    "    for (p, p_target) in zip(Flux.params(value), Flux.params(value_target))\n",
    "        p_target .= (1-TARGET_UPDATE) .* p_target .+ TARGET_UPDATE .* p\n",
    "        @assert !any(isnan.(p_target))\n",
    "    end\n",
    "end\n",
    "\n",
    "function update_value!(value, critics, policy, optim, states::Array{T}) where {T}\n",
    "    parameters = Flux.params(value)\n",
    "    outer_loss = 0\n",
    "    \n",
    "    mu, sigma = forward_policy(policy, states)\n",
    "    actions = policy_sample(mu, sigma)\n",
    "    p = logprobs(mu, sigma, actions)\n",
    "    q = forward_critic(critics, states, squash(actions))\n",
    "    target = q .- ENTROPY_INCENTIVE .* p\n",
    "    \n",
    "    \n",
    "    grads = gradient(parameters) do\n",
    "        loss = Flux.mse(value(states), target)# + L2_REG * sum(norm, parameters)\n",
    "        outer_loss += loss\n",
    "        return loss\n",
    "    end\n",
    "    \n",
    "    Flux.update!(optim, parameters, grads)\n",
    "    @assert !any([any(isnan.(layer.W)) for layer in value])\n",
    "    outer_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_critic! (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_critic!(critic, value_target, optim, states, actions, rewards, next_states, deaths)\n",
    "    parameters = Flux.params(critic)\n",
    "    outer_loss = 0\n",
    "    target = rewards .+ GAMMA .* (.!deaths) .* dropdims(value_target(next_states), dims=1)\n",
    "    @assert !any(isnan.(target))\n",
    "        \n",
    "    grads = gradient(parameters) do\n",
    "        loss = Flux.mse(critic(vcat(states, actions)), target)# + L2_REG * sum(norm, parameters)\n",
    "        outer_loss += loss\n",
    "        return loss\n",
    "    end\n",
    "    \n",
    "    Flux.update!(optim, parameters, grads)\n",
    "    \n",
    "    @assert !any([any(isnan.(layer.W)) for layer in critic])\n",
    "    outer_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_policy! (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_policy!(policy, critics, optim, states::Array{T}) where {T}\n",
    "    parameters = Flux.params(policy)\n",
    "    outer_loss = 0\n",
    "    batch_size = size(states)[2]\n",
    "    unitnoise = T.(rand(Normal(), (ACTION_SPACE, batch_size)))\n",
    "    unitnoise = clamp.(unitnoise, -10, 10) # Don't allow crazy outliers\n",
    "    \n",
    "    grads = gradient(parameters) do\n",
    "        mu, sigma = forward_policy(policy, states)\n",
    "        actions = mu .+ sigma .* unitnoise\n",
    "        q = forward_critic(critics, states, squash(actions))\n",
    "        is = ENTROPY_INCENTIVE * logprobs(mu, sigma, actions)\n",
    "        loss = sum(is .- q) / batch_size #+ L2_REG * sum(norm, parameters)\n",
    "        outer_loss += loss\n",
    "        return loss\n",
    "    end\n",
    "        \n",
    "    Flux.update!(optim, parameters, grads)\n",
    "    @assert !any([any(isnan.(layer.W)) for layer in policy])\n",
    "    outer_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huhu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.5002e-5"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch(memory)\n",
    "    batch = vcat([sample(memory) for _ in 1:BATCH_SIZE])\n",
    "    \n",
    "    # Destructure the batch\n",
    "    state, action, reward, next_state, death = [getindex.(batch, i) for i in 1:5]\n",
    "    state = Flux.batch(state)\n",
    "    next_state = Flux.batch(next_state)\n",
    "    action = Flux.batch(action)\n",
    "    \n",
    "    @assert !any(isnan.(state))\n",
    "    @assert !any(isnan.(action))\n",
    "    \n",
    "    return state, action, reward, next_state, death\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collect_experience! (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function collect_experience!(env, memory, steps)\n",
    "  state = dtype.(env.reset())\n",
    "  total_reward = 0\n",
    "  total_deaths = 0\n",
    "  for _ in 1:steps\n",
    "    action = dtype.(clamp(rand(MvNormal(ACTION_LOW, ACTION_HIGH)), ACTION_LOW, ACTION_HIGH))\n",
    "    next_state, reward, death, _ = env.step(action) # Advance the env\n",
    "\n",
    "    # Convert to dtype\n",
    "    next_state = dtype.(next_state)\n",
    "    reward = dtype(reward)\n",
    "    total_reward += reward\n",
    "\n",
    "    push!(memory, (state, action, reward, next_state, death))\n",
    "    \n",
    "    if death\n",
    "        state = env.reset()\n",
    "        total_deaths += 1\n",
    "    end\n",
    "  end\n",
    "  total_reward / (total_deaths + 1)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function train!(env, memory, optim, policy, critics, value, value_target)\n",
    "  for epoch in 1:EPOCHS\n",
    "    total_reward = 0\n",
    "    total_deaths = 0\n",
    "    total_v_loss = 0\n",
    "    total_q1_loss = 0\n",
    "    total_q2_loss = 0\n",
    "    total_policy_loss = 0\n",
    "    total_entropy = 0\n",
    "    total_iterations = 0\n",
    "    state = dtype.(env.reset())\n",
    "    for i in 1:STEPS_PER_EPOCH\n",
    "        action = act(policy, state) # Act\n",
    "        next_state, reward, death, _ = env.step(action) # Advance the env\n",
    "\n",
    "        # Convert to Float32\n",
    "        next_state = dtype.(next_state)\n",
    "        reward = dtype(reward)\n",
    "\n",
    "        push!(memory, (state, action, reward, next_state, death))\n",
    "        total_reward += reward\n",
    "        if death\n",
    "            state = env.reset()\n",
    "            total_deaths += 1\n",
    "        else\n",
    "            state = next_state\n",
    "        end\n",
    "\n",
    "        if length(memory) > BATCH_SIZE\n",
    "            for i in 1:1\n",
    "                states, actions, rewards, next_states, deaths = batch(memory)\n",
    "                actions = action_to_support(actions)\n",
    "                total_v_loss += update_value!(value, critics, policy, optim, states)\n",
    "                total_q1_loss += update_critic!(critics[1], value_target, optim, states, actions, rewards, next_states, deaths)\n",
    "                total_q2_loss += update_critic!(critics[2], value_target, optim, states, actions, rewards, next_states, deaths)\n",
    "                total_policy_loss += update_policy!(policy, critics, optim, states)\n",
    "                update_value_target!(value_target, value)\n",
    "                @assert(!isnan(total_v_loss))\n",
    "                @assert(!isnan(total_q1_loss))\n",
    "                @assert(!isnan(total_q2_loss))\n",
    "                @assert(!isnan(total_policy_loss))\n",
    "                total_iterations += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    s,a,r,sn,d = batch(memory)\n",
    "    v = mean(value(s))\n",
    "    q1 = mean(critics[1](vcat(s, a)))\n",
    "    q2 = mean(critics[2](vcat(s, a)))\n",
    "    mu, sigma = forward_policy(policy, s)\n",
    "    println(@sprintf(\"v: %f, q1: %f, q2: %f, e: %f\", \n",
    "            v, \n",
    "            q1,\n",
    "            q2,\n",
    "            mean(sigma)))\n",
    "\n",
    "    println(@sprintf(\"I: %d, r: %f, v: %f, q1: %f, q2: %f, p: %f\",\n",
    "            epoch,\n",
    "            total_reward/(total_deaths+1),\n",
    "            total_v_loss/total_iterations,\n",
    "            total_q1_loss/total_iterations,\n",
    "            total_q2_loss/total_iterations,\n",
    "            total_policy_loss/total_iterations))\n",
    "    flush(stdout)\n",
    "  end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.526315789473685"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value, value_target, critics, policy, memory = initialize()\n",
    "collect_experience!(env, memory, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v: 23.654447, q1: 23.426141, q2: 23.430552, e: 0.861843\n",
      "I: 1, r: 24.096386, v: 0.021249, q1: 2000.219431, q2: 2000.684103, p: -23.577358\n",
      "v: 23.295288, q1: 23.304172, q2: 23.346272, e: 0.869510\n",
      "I: 2, r: 26.666667, v: 0.020617, q1: 2016.945288, q2: 2017.399796, p: -23.555325\n",
      "v: 23.768756, q1: 23.635682, q2: 23.659207, e: 0.878101\n",
      "I: 3, r: 27.027027, v: 0.027285, q1: 1983.293353, q2: 1983.859376, p: -23.569312\n",
      "v: 23.518104, q1: 23.616610, q2: 23.668448, e: 0.874863\n",
      "I: 4, r: 28.571429, v: 0.014384, q1: 2000.935017, q2: 2001.343588, p: -23.547004\n",
      "v: 23.674016, q1: 23.589777, q2: 23.634162, e: 0.877567\n",
      "I: 5, r: 26.666667, v: 0.018785, q1: 1949.967180, q2: 1950.388580, p: -23.610086\n",
      "v: 23.548820, q1: 23.441905, q2: 23.467004, e: 0.876182\n",
      "I: 6, r: 25.974026, v: 0.015728, q1: 1997.715843, q2: 1998.098964, p: -23.597711\n",
      "v: 23.476372, q1: 23.493596, q2: 23.517159, e: 0.871869\n",
      "I: 7, r: 27.397260, v: 0.024801, q1: 1988.017182, q2: 1988.453296, p: -23.612672\n",
      "v: 23.872068, q1: 23.654609, q2: 23.665762, e: 0.864501\n",
      "I: 8, r: 25.974026, v: 0.017257, q1: 1988.304605, q2: 1988.674799, p: -23.631402\n",
      "v: 23.760753, q1: 23.545023, q2: 23.531856, e: 0.879174\n",
      "I: 9, r: 23.255814, v: 0.015798, q1: 2014.230745, q2: 2014.651422, p: -23.623765\n",
      "v: 23.722098, q1: 23.347424, q2: 23.299941, e: 0.871481\n",
      "I: 10, r: 24.390244, v: 0.015234, q1: 2004.696153, q2: 2005.115280, p: -23.630767\n",
      "v: 23.661133, q1: 23.769718, q2: 23.804958, e: 0.882278\n",
      "I: 11, r: 27.397260, v: 0.017530, q1: 2039.122933, q2: 2039.672457, p: -23.585850\n",
      "v: 23.255010, q1: 23.287604, q2: 23.264701, e: 0.869664\n",
      "I: 12, r: 27.777778, v: 0.016171, q1: 2000.802243, q2: 2001.186107, p: -23.576579\n",
      "v: 23.647617, q1: 23.373578, q2: 23.317680, e: 0.868468\n",
      "I: 13, r: 25.316456, v: 0.012221, q1: 1993.078374, q2: 1993.388493, p: -23.601579\n",
      "v: 23.875993, q1: 23.643461, q2: 23.588694, e: 0.870623\n",
      "I: 14, r: 24.096386, v: 0.015153, q1: 2018.444009, q2: 2018.790807, p: -23.580196\n",
      "v: 23.610238, q1: 23.454737, q2: 23.399104, e: 0.869730\n",
      "I: 15, r: 25.974026, v: 0.014791, q1: 2048.092800, q2: 2048.509966, p: -23.550890\n",
      "v: 23.501988, q1: 23.464353, q2: 23.386379, e: 0.873638\n",
      "I: 16, r: 22.988506, v: 0.010258, q1: 2000.045501, q2: 2000.395029, p: -23.550645\n",
      "v: 23.406187, q1: 23.656539, q2: 23.605845, e: 0.873504\n",
      "I: 17, r: 25.974026, v: 0.010829, q1: 2013.961368, q2: 2014.231841, p: -23.556231\n",
      "v: 23.465681, q1: 23.288348, q2: 23.132229, e: 0.876604\n",
      "I: 18, r: 26.666667, v: 0.015031, q1: 1989.582880, q2: 1989.859459, p: -23.568025\n",
      "v: 23.920991, q1: 23.660984, q2: 23.515657, e: 0.875706\n",
      "I: 19, r: 25.974026, v: 0.011048, q1: 2015.019985, q2: 2015.310128, p: -23.552394\n",
      "v: 23.611612, q1: 23.553068, q2: 23.419979, e: 0.874631\n",
      "I: 20, r: 27.397260, v: 0.014358, q1: 1983.353159, q2: 1983.628384, p: -23.587275\n",
      "v: 23.513811, q1: 23.460330, q2: 23.370289, e: 0.879583\n",
      "I: 21, r: 27.397260, v: 0.014352, q1: 2012.482412, q2: 2012.799286, p: -23.573578\n",
      "v: 23.830048, q1: 23.663063, q2: 23.560222, e: 0.875743\n",
      "I: 22, r: 25.974026, v: 0.012625, q1: 1968.125820, q2: 1968.494474, p: -23.611812\n",
      "v: 23.643122, q1: 23.339886, q2: 23.237926, e: 0.877573\n",
      "I: 23, r: 26.666667, v: 0.015775, q1: 2018.807234, q2: 2019.109250, p: -23.617183\n",
      "v: 23.515949, q1: 23.362887, q2: 23.292908, e: 0.876152\n",
      "I: 24, r: 26.666667, v: 0.012283, q1: 2002.954705, q2: 2003.190971, p: -23.621068\n",
      "v: 23.866840, q1: 23.463890, q2: 23.340574, e: 0.882405\n",
      "I: 25, r: 25.974026, v: 0.015651, q1: 2017.926017, q2: 2018.241483, p: -23.611790\n",
      "v: 23.468649, q1: 23.505182, q2: 23.462373, e: 0.877590\n",
      "I: 26, r: 24.691358, v: 0.018630, q1: 1986.082759, q2: 1986.376383, p: -23.638370\n",
      "v: 23.628229, q1: 23.460863, q2: 23.370759, e: 0.876111\n",
      "I: 27, r: 25.641026, v: 0.015363, q1: 2008.664484, q2: 2009.064871, p: -23.638895\n",
      "v: 23.668108, q1: 23.661219, q2: 23.607048, e: 0.871603\n",
      "I: 28, r: 27.027027, v: 0.011017, q1: 1989.753533, q2: 1990.045443, p: -23.666045\n",
      "v: 23.600607, q1: 23.633554, q2: 23.589873, e: 0.876466\n",
      "I: 29, r: 26.666667, v: 0.014405, q1: 2037.086635, q2: 2037.421330, p: -23.656981\n",
      "v: 23.697327, q1: 23.723407, q2: 23.659134, e: 0.874609\n",
      "I: 30, r: 23.809524, v: 0.011115, q1: 1990.952622, q2: 1991.251358, p: -23.675559\n",
      "v: 23.712950, q1: 23.555327, q2: 23.492324, e: 0.869252\n",
      "I: 31, r: 24.096386, v: 0.012740, q1: 2030.605291, q2: 2030.834916, p: -23.678105\n",
      "v: 23.781314, q1: 23.807413, q2: 23.792433, e: 0.866865\n",
      "I: 32, r: 25.000000, v: 0.010187, q1: 2001.984054, q2: 2002.258842, p: -23.696105\n",
      "v: 23.557099, q1: 23.329743, q2: 23.252375, e: 0.882184\n",
      "I: 33, r: 27.397260, v: 0.013013, q1: 2028.058609, q2: 2028.317460, p: -23.691995\n",
      "v: 23.683081, q1: 23.665529, q2: 23.659261, e: 0.862577\n",
      "I: 34, r: 25.316456, v: 0.012043, q1: 2005.830342, q2: 2006.111183, p: -23.710701\n",
      "v: 23.785984, q1: 23.410055, q2: 23.344457, e: 0.871376\n",
      "I: 35, r: 24.691358, v: 0.013080, q1: 2011.512620, q2: 2011.726824, p: -23.707470\n",
      "v: 23.728088, q1: 23.691346, q2: 23.659067, e: 0.871193\n",
      "I: 36, r: 25.974026, v: 0.012889, q1: 2026.275828, q2: 2026.557108, p: -23.708219\n",
      "v: 23.734256, q1: 23.513384, q2: 23.482856, e: 0.877744\n",
      "I: 37, r: 26.315789, v: 0.010507, q1: 1995.444269, q2: 1995.678019, p: -23.745891\n",
      "v: 23.756395, q1: 23.799194, q2: 23.802892, e: 0.882247\n",
      "I: 38, r: 26.666667, v: 0.013579, q1: 2013.070380, q2: 2013.354769, p: -23.754068\n",
      "v: 23.404493, q1: 23.510583, q2: 23.499691, e: 0.866789\n",
      "I: 39, r: 25.316456, v: 0.012676, q1: 2011.644400, q2: 2011.820204, p: -23.768194\n",
      "v: 23.611374, q1: 23.555138, q2: 23.528538, e: 0.865358\n",
      "I: 40, r: 22.727273, v: 0.014556, q1: 2034.465319, q2: 2034.712884, p: -23.762577\n",
      "v: 23.714614, q1: 23.567484, q2: 23.530020, e: 0.871378\n",
      "I: 41, r: 27.027027, v: 0.011804, q1: 2066.840662, q2: 2067.036114, p: -23.711407\n",
      "v: 23.669038, q1: 23.694440, q2: 23.682196, e: 0.873760\n",
      "I: 42, r: 27.777778, v: 0.012566, q1: 2016.507842, q2: 2016.766173, p: -23.711622\n",
      "v: 23.438618, q1: 23.528946, q2: 23.504444, e: 0.870801\n",
      "I: 43, r: 28.169014, v: 0.013861, q1: 2082.773937, q2: 2083.048978, p: -23.669727\n",
      "v: 23.640949, q1: 23.467145, q2: 23.435388, e: 0.883779\n",
      "I: 44, r: 26.315789, v: 0.013625, q1: 2045.742354, q2: 2046.045875, p: -23.632089\n",
      "v: 23.545599, q1: 23.427942, q2: 23.384269, e: 0.878781\n",
      "I: 45, r: 26.315789, v: 0.011608, q1: 1989.891457, q2: 1990.182442, p: -23.670077\n",
      "v: 24.005412, q1: 23.726701, q2: 23.698518, e: 0.868746\n",
      "I: 46, r: 23.809524, v: 0.011703, q1: 2033.626796, q2: 2033.853880, p: -23.653927\n",
      "v: 23.602571, q1: 23.541641, q2: 23.512569, e: 0.878442\n",
      "I: 47, r: 24.390244, v: 0.010730, q1: 1982.256181, q2: 1982.490698, p: -23.685836\n",
      "v: 23.771783, q1: 23.764343, q2: 23.753560, e: 0.873237\n",
      "I: 48, r: 25.641026, v: 0.013516, q1: 2010.022240, q2: 2010.277438, p: -23.705516\n",
      "v: 23.662541, q1: 23.565720, q2: 23.543798, e: 0.870141\n",
      "I: 49, r: 26.666667, v: 0.012146, q1: 2018.031016, q2: 2018.280624, p: -23.715225\n",
      "v: 23.663225, q1: 23.733261, q2: 23.740021, e: 0.877499\n",
      "I: 50, r: 24.096386, v: 0.011814, q1: 2026.016526, q2: 2026.267403, p: -23.707747\n",
      "v: 23.733525, q1: 23.460751, q2: 23.425299, e: 0.886802\n",
      "I: 51, r: 28.169014, v: 0.012596, q1: 2059.253665, q2: 2059.489061, p: -23.681439\n",
      "v: 23.682566, q1: 23.582322, q2: 23.569817, e: 0.874695\n",
      "I: 52, r: 25.974026, v: 0.009953, q1: 2043.564569, q2: 2043.837011, p: -23.639984\n",
      "v: 23.861615, q1: 23.684472, q2: 23.642889, e: 0.884771\n",
      "I: 53, r: 26.315789, v: 0.011340, q1: 2010.726968, q2: 2010.941862, p: -23.654071\n",
      "v: 23.558221, q1: 23.513370, q2: 23.508280, e: 0.871989\n",
      "I: 54, r: 27.397260, v: 0.011339, q1: 2004.882662, q2: 2005.125681, p: -23.659314\n",
      "v: 23.673040, q1: 23.417091, q2: 23.392902, e: 0.873694\n",
      "I: 55, r: 24.390244, v: 0.010136, q1: 2040.721595, q2: 2040.987780, p: -23.635946\n",
      "v: 23.416350, q1: 23.407677, q2: 23.410929, e: 0.879875\n",
      "I: 56, r: 27.397260, v: 0.013524, q1: 2039.226122, q2: 2039.446454, p: -23.611909\n",
      "v: 23.579057, q1: 23.476298, q2: 23.463177, e: 0.864744\n",
      "I: 57, r: 27.777778, v: 0.010856, q1: 1993.128471, q2: 1993.399927, p: -23.632703\n",
      "v: 24.025141, q1: 23.728111, q2: 23.709128, e: 0.864206\n",
      "I: 58, r: 25.316456, v: 0.011615, q1: 1973.378412, q2: 1973.586969, p: -23.674802\n",
      "v: 23.573849, q1: 23.525434, q2: 23.530602, e: 0.876812\n",
      "I: 59, r: 26.315789, v: 0.011255, q1: 2021.431808, q2: 2021.668947, p: -23.673060\n",
      "v: 23.880349, q1: 23.631358, q2: 23.622457, e: 0.867702\n",
      "I: 60, r: 24.691358, v: 0.013913, q1: 2020.595620, q2: 2020.842680, p: -23.670362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v: 23.527652, q1: 23.253805, q2: 23.216301, e: 0.880239\n",
      "I: 61, r: 25.000000, v: 0.009378, q1: 1986.794766, q2: 1987.014500, p: -23.711093\n",
      "v: 23.429945, q1: 23.453890, q2: 23.465711, e: 0.885897\n",
      "I: 62, r: 25.316456, v: 0.019108, q1: 2037.714394, q2: 2037.934027, p: -23.695766\n",
      "v: 23.902212, q1: 23.682968, q2: 23.667632, e: 0.876424\n",
      "I: 63, r: 26.315789, v: 0.010739, q1: 2003.524029, q2: 2003.757434, p: -23.712395\n",
      "v: 23.509436, q1: 23.643754, q2: 23.662922, e: 0.875773\n",
      "I: 64, r: 23.809524, v: 0.008513, q1: 2020.509797, q2: 2020.720828, p: -23.709834\n",
      "v: 23.587453, q1: 23.455529, q2: 23.443720, e: 0.872804\n",
      "I: 65, r: 27.027027, v: 0.011002, q1: 2007.602858, q2: 2007.837710, p: -23.735484\n",
      "v: 23.845513, q1: 23.780273, q2: 23.796526, e: 0.878015\n",
      "I: 66, r: 22.471910, v: 0.011240, q1: 2021.515386, q2: 2021.730404, p: -23.730663\n",
      "v: 23.659181, q1: 23.725662, q2: 23.743894, e: 0.867560\n",
      "I: 67, r: 26.666667, v: 0.009698, q1: 2015.401577, q2: 2015.604108, p: -23.769540\n",
      "v: 23.659844, q1: 23.634852, q2: 23.623314, e: 0.868903\n",
      "I: 68, r: 24.096386, v: 0.011133, q1: 2046.094232, q2: 2046.359902, p: -23.749197\n",
      "v: 23.651023, q1: 23.481397, q2: 23.474083, e: 0.872944\n",
      "I: 69, r: 24.691358, v: 0.012211, q1: 1992.604924, q2: 1992.769892, p: -23.771218\n",
      "v: 23.745902, q1: 23.788300, q2: 23.821283, e: 0.869687\n",
      "I: 70, r: 32.258065, v: 0.011987, q1: 1987.046501, q2: 1987.344165, p: -23.812450\n",
      "v: 23.928935, q1: 23.928209, q2: 23.945408, e: 0.871844\n",
      "I: 71, r: 27.027027, v: 0.009325, q1: 2040.984289, q2: 2041.207631, p: -23.796799\n",
      "v: 23.615895, q1: 23.698181, q2: 23.731935, e: 0.871844\n",
      "I: 72, r: 25.974026, v: 0.013902, q1: 2064.581179, q2: 2064.786050, p: -23.768089\n",
      "v: 23.592693, q1: 23.333575, q2: 23.323056, e: 0.869264\n",
      "I: 73, r: 25.974026, v: 0.009810, q1: 2001.142913, q2: 2001.355093, p: -23.804099\n",
      "v: 23.971529, q1: 23.818590, q2: 23.810533, e: 0.878566\n",
      "I: 74, r: 25.974026, v: 0.008568, q1: 2041.571488, q2: 2041.781553, p: -23.785588\n",
      "v: 23.751142, q1: 23.592209, q2: 23.604237, e: 0.881918\n",
      "I: 75, r: 24.390244, v: 0.009287, q1: 2060.735847, q2: 2060.948322, p: -23.760032\n",
      "v: 24.149258, q1: 23.547723, q2: 23.497932, e: 0.873440\n",
      "I: 76, r: 28.169014, v: 0.008864, q1: 2035.712653, q2: 2035.916946, p: -23.756975\n",
      "v: 24.075054, q1: 23.901244, q2: 23.906019, e: 0.884786\n",
      "I: 77, r: 25.974026, v: 0.009037, q1: 2027.329696, q2: 2027.527285, p: -23.752554\n",
      "v: 23.659329, q1: 23.544989, q2: 23.522685, e: 0.871822\n",
      "I: 78, r: 28.169014, v: 0.009199, q1: 1999.898799, q2: 2000.144130, p: -23.767897\n",
      "v: 23.642097, q1: 23.551811, q2: 23.564490, e: 0.872704\n",
      "I: 79, r: 25.641026, v: 0.008923, q1: 2032.522462, q2: 2032.791199, p: -23.785612\n",
      "v: 23.755971, q1: 23.500236, q2: 23.480133, e: 0.880341\n",
      "I: 80, r: 26.315789, v: 0.012013, q1: 2053.754645, q2: 2053.963116, p: -23.777408\n",
      "v: 23.933515, q1: 23.550612, q2: 23.493781, e: 0.871830\n",
      "I: 81, r: 23.255814, v: 0.011810, q1: 2028.575932, q2: 2028.801089, p: -23.771543\n",
      "v: 23.704548, q1: 23.617119, q2: 23.608560, e: 0.868515\n",
      "I: 82, r: 29.411765, v: 0.008964, q1: 2035.197211, q2: 2035.441268, p: -23.763623\n",
      "v: 23.731225, q1: 23.668250, q2: 23.672858, e: 0.864338\n",
      "I: 83, r: 26.315789, v: 0.008503, q1: 2054.698332, q2: 2054.952573, p: -23.742460\n",
      "v: 23.663659, q1: 23.567056, q2: 23.556710, e: 0.886932\n",
      "I: 84, r: 25.641026, v: 0.008757, q1: 2001.484142, q2: 2001.693480, p: -23.777113\n",
      "v: 23.879930, q1: 23.643132, q2: 23.615670, e: 0.886450\n",
      "I: 85, r: 23.529412, v: 0.009240, q1: 2038.936290, q2: 2039.189617, p: -23.776240\n",
      "v: 23.807795, q1: 23.638523, q2: 23.622243, e: 0.871315\n",
      "I: 86, r: 25.000000, v: 0.008373, q1: 1981.103684, q2: 1981.353053, p: -23.814063\n",
      "v: 23.561812, q1: 23.462042, q2: 23.457899, e: 0.889063\n",
      "I: 87, r: 25.974026, v: 0.008494, q1: 2020.867357, q2: 2021.105402, p: -23.822570\n",
      "v: 23.802327, q1: 23.510638, q2: 23.499195, e: 0.869181\n",
      "I: 88, r: 25.316456, v: 0.010655, q1: 2060.429575, q2: 2060.655663, p: -23.789939\n",
      "v: 23.975760, q1: 23.756846, q2: 23.765132, e: 0.877849\n",
      "I: 89, r: 27.027027, v: 0.007780, q1: 2044.291330, q2: 2044.479845, p: -23.777864\n",
      "v: 23.851337, q1: 23.710398, q2: 23.717430, e: 0.879148\n",
      "I: 90, r: 25.974026, v: 0.007790, q1: 2018.756416, q2: 2018.993008, p: -23.790099\n",
      "v: 23.760583, q1: 23.668494, q2: 23.675342, e: 0.879877\n",
      "I: 91, r: 25.316456, v: 0.009138, q1: 2033.225643, q2: 2033.490994, p: -23.788165\n",
      "v: 23.982263, q1: 23.868125, q2: 23.882617, e: 0.871881\n",
      "I: 92, r: 27.777778, v: 0.006815, q1: 2030.675824, q2: 2030.843020, p: -23.779626\n",
      "v: 23.542529, q1: 23.301484, q2: 23.302340, e: 0.872051\n",
      "I: 93, r: 27.027027, v: 0.010892, q1: 2037.753055, q2: 2038.006006, p: -23.789016\n",
      "v: 23.666890, q1: 23.590633, q2: 23.633585, e: 0.888668\n",
      "I: 94, r: 25.000000, v: 0.010331, q1: 2042.380534, q2: 2042.587890, p: -23.779310\n",
      "v: 23.905787, q1: 23.785631, q2: 23.798583, e: 0.882203\n",
      "I: 95, r: 25.641026, v: 0.011423, q1: 2048.019740, q2: 2048.225943, p: -23.761609\n",
      "v: 23.759763, q1: 23.678073, q2: 23.685902, e: 0.879101\n",
      "I: 96, r: 27.397260, v: 0.012543, q1: 2016.677991, q2: 2016.895982, p: -23.789685\n",
      "v: 23.505793, q1: 23.356330, q2: 23.335866, e: 0.873278\n",
      "I: 97, r: 27.397260, v: 0.007779, q1: 2017.741768, q2: 2017.950966, p: -23.797857\n",
      "v: 23.783273, q1: 23.455221, q2: 23.424914, e: 0.875619\n",
      "I: 98, r: 24.390244, v: 0.011100, q1: 2038.656680, q2: 2038.880130, p: -23.793919\n",
      "v: 23.840413, q1: 23.595953, q2: 23.591230, e: 0.876484\n",
      "I: 99, r: 25.316456, v: 0.011243, q1: 2052.983664, q2: 2053.282794, p: -23.769039\n",
      "v: 23.848308, q1: 23.640407, q2: 23.622488, e: 0.868865\n",
      "I: 100, r: 27.027027, v: 0.008899, q1: 1988.501322, q2: 1988.789268, p: -23.807203\n"
     ]
    }
   ],
   "source": [
    "train!(env, memory, optim, policy, critics, value, value_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test(env, policy)\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    for _ in 1:5000\n",
    "        mu, sigma = forward_policy(policy, state)\n",
    "        state, reward, death, _ = env.step(mu)\n",
    "        total_reward += reward\n",
    "        env.render()\n",
    "        if death\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    total_reward\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@BSON.save \"models.bson\" Dict(\n",
    "    :value => value,\n",
    "    :value_target => value_target,\n",
    "    :critics => critics,\n",
    "    :policy => policy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.0593887521755381 -0.09837611675025143 … 0.011800205368475647 -0.19544651568152593; -0.7859106243879304 -1.4163999185471952 … 0.02471146324088716 -0.8055429254736141; -0.018139650155244755 0.1221037720307057 … -0.03026086376533901 0.029718731219978547; 0.4925133549958805 1.0070555566413861 … 0.012829738314209124 0.20123916341663578], [8.416118698940394 5.8421170146112615 … 4.956979129541407 8.013060997234167], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [-0.08039334550728447 -0.13071587094306414 … 0.00946937420570149 -0.21736059562231513; -1.0502296665873185 -1.6169877096406347 … -0.1165415581387079 -1.0957039970394593; -0.004989776396819065 0.1445471776105656 … -0.028073328105376015 0.036913824237685744; 0.6574936879212845 1.122170278992995 … 0.10937678299814976 0.35975465088535985], Bool[0, 0, 0, 0, 0, 0, 0, 0, 0, 0  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 10000\n",
    "s,a,r,sa,d = batch(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
